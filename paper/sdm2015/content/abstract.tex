
\begin{abstract}
%\small\baselineskip=9pt
Increasingly, organizations have employed methods to understand unstructured text across the web.
Entity resolution is used to identify mentions in large, streaming text corpora.
Sampling-based entity resolution using Markov Chain Monte Carlo (MCMC) techniques guarantees convergence to a stationary distribution and can jump out of local optimum.
When performing entity resolution over streams of incoming data, the growing quantity of data amplifies two main issues.
First, because the sampling process is random, many iterations are waisted attempting to resolve unambiguous entities.
Second, the quadratic runtime for scoring entities becomes prohibitive for largest entities.
%When new documents are continuously updated the above issues are exacerbated.
Frequent streaming updates from the web exacerbate these difficulties.
In this paper, we discuss the creation a proposal optimizer, in the spirit of database optimizers.
This optimizer observes the proposal updates to the entity resolution model
then makes recommendations to improve the processing and storage of the model.
We motivate the use of compression techniques to reduce the amount of processing when scoring MCMC updates proposal.
We also discuss statistical early-stopping techniques for scoring entities.
We describe our initial progress over a large entity resolution data set and
how an optimizer can improve performance when processing entity resolution streams.


\end{abstract}
