
\section{Algorithms}

In this section we will describe XXX algorithms for entity sampling.
The main method we use to improve the computation speed is to reduce the
number of comparisons we make for large entity clusters.
We additionally discuss methods to improve the performance of algorithms
over time by collecting statistics from the processes.

\textbf{Random Iterator.} This method shuffles the mentions in both the
source and destination entity clusters when doing pairwise comparisons. 

\textbf{Sorted Iterator.} This method sorts them mentions in both the source
and destination entity clusters when performing pairwise comparisons.

\textbf{SubSample Iterator.} This method only samples $M$ mentions from the
source and destination entities clusters when performing pairwise comparisons.

\textbf{Top-K SubSample Iterator.} This method uses a priority queue to sort
the mentions and only performs comparisons for the first $M$ values.

\textbf{Blocked Iterator.} This method performs blocking on the mentions in the
source and destination entities and takes the average gain from pairwise
comparisons inside each block .


Further, We examine active learning techniques to adjust threshold sizes based on statistics collected while running the algorithms.

We collect the following statistics from each training run:

Success and failure
Data set size.
Number of uniques tokens.
Average pairwise score between mentions.
Maximum pairwise score between mentions.
Minimum pairwise score between mentions.
Variable pairwise score between mentions.
Mention Token tfidf scores.
\ceg{Generailze the feature explaination and move it to the implementation section}

Using this information we train a decision tree classsifier to minimize the 
pairwise comparisons in the score function.
The classifier is also constrained by the accuracy of the decision tree as 
approximate methods are less accurate.
More formally \ellipse

The result of this classifier is two-fold.
First, we have a classifier to choose the optimal algorithm for each proposal.
Second, we have an active learning feed-back loop for algorithms with 
thresholds.
We emperically study both of these outcomes.



